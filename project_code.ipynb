{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5099197a-43e3-4dec-b76d-8a5780cc63d5",
   "metadata": {},
   "source": [
    "# DGEB Final Project Notebook: Traditional Models for Convergent Enzyme Classification\n",
    "\n",
    "## Authors: Mahbuba Tasmin & Bryn Reimer  \n",
    "Course: CS 690U â€” Spring 2025  \n",
    "Date: April 2025\n",
    "\n",
    "## Objective\n",
    "\n",
    "We aim to benchmark the performance of the following traditional approaches:\n",
    "- **Logistic regression** trained on one-hot encoded DNA sequences (512 bp max).\n",
    "- **Logistic regression** trained on $k$-mer count features (e.g., 4-mers).\n",
    "- **BLAST**-based nearest-neighbor prediction using top alignment match from training data.\n",
    "- **Cross-validation** to assess generalization capability on the training set.\n",
    "\n",
    "The remainder of this notebook is structured as follows:\n",
    "1. Dataset loading and preprocessing\n",
    "2. One-hot encoding pipeline + logistic regression\n",
    "3. $k$-mer encoding variant\n",
    "4. Cross-validation evaluation\n",
    "5. BLAST-based baseline\n",
    "6. Comparative performance summary and interpretations\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0283731e-5103-4185-999c-266d4aa7d3ea",
   "metadata": {},
   "source": [
    "## download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "084476fc-0d30-4127-b621-ff6a940a4cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from datasets import DatasetDict\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84cc21dc-8d65-46f8-9518-abd6f6537580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4b624ba8c149b6a6e2471d6432de56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08107ce891a64a0a982f62454905b945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"parquet\",\n",
    "    data_files={\n",
    "        \"train\": [\n",
    "            \"ec_classification_dna_data/test-00000-of-00001.parquet\",\n",
    "            \"ec_classification_dna_data/train-00000-of-00001.parquet\",\n",
    "        ],\n",
    "        \"test\": \"./ec_classification_dna_data/test-00000-of-00001.parquet\",\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e2f25db-73d8-4d44-a431-84d3622360af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Entry', 'Label', 'Sequence'],\n",
      "        num_rows: 640\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Entry', 'Label', 'Sequence'],\n",
      "        num_rows: 128\n",
      "    })\n",
      "})\n",
      "{'Entry': 'A0A0H2XEA6', 'Label': '1.14.14.18', 'Sequence': 'TCAAGGACGTGCCTCCGCTGCCAGGCAGGTGTGGAAATGGGCAAACATGGCCTGCGCGCCGGCGATGGCGTCGGCACGCGCCGCTGCGCTCTGCAGGCGTTGCTCGAGCACCGCCTGAAAGCGCCGCCAGCCGGCCGGGTCTTCGTCGGCCAGCTCGAAATAGTGCAATGCATGCGCCAGGCCCGGCTGACGTTTGCGCAGCATGCGTGCAATCACCCGGCCACCCAGCTGAGAGCCTTCGATGACATACAGCATGCCCCAGCGCGCCGCCTCGCTGCTGGCCGGCGGCGGCACGGCGGCATCGACGGGTTGGCCGAGCACGCGCAGATCCTCCCGCAAGGCCGGCACCCGGCGGCGGTACTGCCAGCCGCTGCCCACCAGCGTCACCAGCCAGTCGCTCAGCTGTTCTTCGAAACCGGCCAGCAGCCGGTGATGCCGGCGCAGCACCTGCGCGTAGGTATCGGCGTCGATGTGGCCCTGCCCCAGCGCCTGCATCAG'}\n"
     ]
    }
   ],
   "source": [
    "#explore dataset\n",
    "\n",
    "# Peek at the structure\n",
    "print(dataset)\n",
    "print(dataset[\"train\"][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3926d7e-a32d-4649-868b-8aac6390b080",
   "metadata": {},
   "source": [
    "## one-hot encoding based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89afc527-307e-4b1e-8b9e-6642be8242e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##one hot encoding - 512 bp (we can expand)\n",
    "def one_hot_encode_dna(seq, max_len=512):\n",
    "    bases = \"ACGT\"\n",
    "    base_to_idx = {b: i for i, b in enumerate(bases)}\n",
    "    encoding = np.zeros((max_len, len(bases)))\n",
    "    for i, base in enumerate(seq[:max_len]):\n",
    "        if base in base_to_idx:\n",
    "            encoding[i, base_to_idx[base]] = 1.0\n",
    "    return encoding.flatten()  # shape: 512 * 4 = 2048\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52bc2098-a80d-4173-a6f3-e5246e0e8696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 640 Test size: 128\n",
      "        Entry       Label                                           Sequence\n",
      "0  A0A0H2XEA6  1.14.14.18  TCAAGGACGTGCCTCCGCTGCCAGGCAGGTGTGGAAATGGGCAAAC...\n",
      "1      Q5AD07    1.15.1.1  ATGAAGTATTTGTCCATTTTCTTACTTGCTACTTTTGCTTTGGCTG...\n",
      "2      O74831    1.16.3.1  ATGCAGTCTTTGCGAGCAGCCTTTCGCAGACGAACCCCAATTTTTT...\n",
      "3      O46310    1.17.4.1  ATGAAACCGGTTGCGGCTGGCGCCGAGGTGCTGCCGGCGGACAAGG...\n",
      "4      Q8PU58    1.5.98.3  ATGTCTGGAATAATTGATAGCTATATACCGGTTGCCATATTTCTTG...\n"
     ]
    }
   ],
   "source": [
    "## load dataset and convert to pandas\n",
    "# Convert Hugging Face DatasetDict to pandas\n",
    "df_train = pd.DataFrame(dataset[\"train\"])\n",
    "df_test = pd.DataFrame(dataset[\"test\"])\n",
    "\n",
    "print(\"Train size:\", len(df_train), \"Test size:\", len(df_test))\n",
    "print(df_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43ac1c78-fa42-4773-bde7-00f9da5ccb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (640, 2048)\n"
     ]
    }
   ],
   "source": [
    "## apply encoding to all seq\n",
    "# Apply to training and test data\n",
    "X_train = np.stack(df_train[\"Sequence\"].map(one_hot_encode_dna))\n",
    "X_test = np.stack(df_test[\"Sequence\"].map(one_hot_encode_dna))\n",
    "\n",
    "# Check shape\n",
    "print(\"X_train shape:\", X_train.shape)  # Expect (640, 2048)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd667c87-e672-4e99-8e23-f3e4c4611553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['1.14.14.18' '1.15.1.1' '1.16.3.1' '1.17.4.1' '1.5.98.3' '1.8.3.2'\n",
      " '2.1.1.354' '2.1.1.360' '2.1.1.37' '2.1.1.72' '2.1.1.77' '2.1.1.86'\n",
      " '2.1.3.15' '2.3.1.225' '2.3.1.269' '2.3.1.48' '2.3.1.51' '2.3.2.23'\n",
      " '2.3.2.26' '2.3.2.27' '2.3.2.31' '2.4.1.109' '2.4.1.198' '2.4.2.31'\n",
      " '2.5.1.18' '2.7.1.107' '2.7.1.21' '2.7.1.33' '2.7.1.67' '2.7.10.1'\n",
      " '2.7.10.2' '2.7.11.1' '2.7.11.25' '2.7.13.3' '2.7.4.3' '2.7.6.1'\n",
      " '2.7.7.108' '2.7.7.19' '2.7.7.48' '2.7.7.49' '2.7.7.6' '2.7.7.65'\n",
      " '2.7.7.7' '2.7.8.7' '2.8.1.13' '3.1.1.1' '3.1.1.3' '3.1.1.32' '3.1.1.4'\n",
      " '3.1.1.96' '3.1.11.2' '3.1.11.6' '3.1.12.1' '3.1.13.4' '3.1.21.10'\n",
      " '3.1.21.4' '3.1.26.3' '3.1.26.4' '3.1.26.5' '3.1.3.16' '3.1.3.18'\n",
      " '3.1.3.2' '3.1.3.3' '3.1.3.48' '3.1.3.5' '3.1.4.12' '3.1.4.35' '3.1.4.4'\n",
      " '3.1.4.52' '3.2.1.1' '3.2.1.14' '3.2.1.17' '3.2.1.18' '3.2.1.22'\n",
      " '3.2.1.23' '3.2.1.35' '3.2.1.39' '3.2.1.4' '3.2.1.52' '3.2.1.55'\n",
      " '3.2.1.78' '3.2.1.8' '3.2.1.96' '3.2.2.22' '3.2.2.6' '3.4.19.12'\n",
      " '3.4.21.105' '3.4.22.49' '3.4.23.36' '3.5.1.28' '3.5.1.98' '3.5.2.6'\n",
      " '3.6.1.1' '3.6.1.13' '3.6.1.23' '3.6.1.5' '3.6.1.9' '3.6.4.12' '3.6.4.13'\n",
      " '3.8.1.2' '4.2.1.1' '4.2.1.10' '4.2.1.2' '4.2.1.20' '4.2.2.2' '4.2.2.3'\n",
      " '4.2.2.n1' '4.4.1.3' '4.6.1.1' '4.6.1.16' '4.6.1.2' '5.2.1.8' '5.3.4.1'\n",
      " '5.4.99.5' '5.6.2.2' '5.6.2.4' '6.1.1.19' '6.3.2.4' '6.3.4.19' '6.3.5.2'\n",
      " '6.3.5.5' '6.5.1.1' '6.5.1.3' '7.1.1.2' '7.1.1.8' '7.1.1.9' '7.1.2.2'\n",
      " '7.2.1.1']\n"
     ]
    }
   ],
   "source": [
    "## encode ec numbers as integer labels\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(df_train[\"Label\"])\n",
    "y_test = le.transform(df_test[\"Label\"])\n",
    "\n",
    "# Optional: Show label classes\n",
    "print(\"Classes:\", le.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb9ac30-deff-46d6-98f7-5b3f1add0043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".00774938\n",
      "Epoch 278, change: 0.00802632\n",
      "Epoch 279, change: 0.02109597\n",
      "Epoch 280, change: 0.01944719\n",
      "Epoch 281, change: 0.01083489\n",
      "Epoch 282, change: 0.00198825\n",
      "Epoch 283, change: 0.00265499\n",
      "Epoch 284, change: 0.00523688\n",
      "Epoch 285, change: 0.02410493\n",
      "Epoch 286, change: 0.01051703\n",
      "Epoch 287, change: 0.01796740\n",
      "Epoch 288, change: 0.01975695\n",
      "Epoch 289, change: 0.00055037\n",
      "Epoch 290, change: 0.01675781\n",
      "Epoch 291, change: 0.01345648\n",
      "Epoch 292, change: 0.01774485\n",
      "Epoch 293, change: 0.00371184\n",
      "Epoch 294, change: 0.00944973\n",
      "Epoch 295, change: 0.00994424\n",
      "Epoch 296, change: 0.00454848\n",
      "Epoch 297, change: 0.01219804\n",
      "Epoch 298, change: 0.01461690\n",
      "Epoch 299, change: 0.00327917\n",
      "Epoch 300, change: 0.01568474\n",
      "Epoch 301, change: 0.01067470\n",
      "Epoch 302, change: 0.00463764\n",
      "Epoch 303, change: 0.00370793\n",
      "Epoch 304, change: 0.00146539\n",
      "Epoch 305, change: 0.01473640\n",
      "Epoch 306, change: 0.01535496\n",
      "Epoch 307, change: 0.01497194\n",
      "Epoch 308, change: 0.01596771\n",
      "Epoch 309, change: 0.01857539\n",
      "Epoch 310, change: 0.02243267\n",
      "Epoch 311, change: 0.00533215\n",
      "Epoch 312, change: 0.00555492\n",
      "Epoch 313, change: 0.00248990\n",
      "Epoch 314, change: 0.01852155\n",
      "Epoch 315, change: 0.01700467\n",
      "Epoch 316, change: 0.00098646\n",
      "Epoch 317, change: 0.00530170\n",
      "Epoch 318, change: 0.00088519\n",
      "Epoch 319, change: 0.01562319\n",
      "Epoch 320, change: 0.00784951\n",
      "Epoch 321, change: 0.00111645\n",
      "Epoch 322, change: 0.00217498\n",
      "Epoch 323, change: 0.01181338\n",
      "Epoch 324, change: 0.01070649\n",
      "Epoch 325, change: 0.00104229\n",
      "Epoch 326, change: 0.01263555\n",
      "Epoch 327, change: 0.01434388\n",
      "Epoch 328, change: 0.00323699\n",
      "Epoch 329, change: 0.01856608\n",
      "Epoch 330, change: 0.01783238\n",
      "Epoch 331, change: 0.02226731\n",
      "Epoch 332, change: 0.01112984\n",
      "Epoch 333, change: 0.03659080\n",
      "Epoch 334, change: 0.02307546\n",
      "Epoch 335, change: 0.01957125\n",
      "Epoch 336, change: 0.02090537\n",
      "Epoch 337, change: 0.01318983\n",
      "Epoch 338, change: 0.00367071\n",
      "Epoch 339, change: 0.02165292\n",
      "Epoch 340, change: 0.01668310\n",
      "Epoch 341, change: 0.00301019\n",
      "Epoch 342, change: 0.01453653\n",
      "Epoch 343, change: 0.01653657\n",
      "Epoch 344, change: 0.01057950\n",
      "Epoch 345, change: 0.03042483\n",
      "Epoch 346, change: 0.01782811\n",
      "Epoch 347, change: 0.00287507\n",
      "Epoch 348, change: 0.01270850\n",
      "Epoch 349, change: 0.01138989\n",
      "Epoch 350, change: 0.00095433\n",
      "Epoch 351, change: 0.00217746\n",
      "Epoch 352, change: 0.00146091\n",
      "Epoch 353, change: 0.00079249\n",
      "Epoch 354, change: 0.00123298\n",
      "Epoch 355, change: 0.00135975\n",
      "Epoch 356, change: 0.01470128\n",
      "Epoch 357, change: 0.00793229\n",
      "Epoch 358, change: 0.01393401\n",
      "Epoch 359, change: 0.00145837\n",
      "Epoch 360, change: 0.00376617\n",
      "Epoch 361, change: 0.00936514\n",
      "Epoch 362, change: 0.02065061\n",
      "Epoch 363, change: 0.00061611\n",
      "Epoch 364, change: 0.01804191\n",
      "Epoch 365, change: 0.01494692\n",
      "Epoch 366, change: 0.00949769\n",
      "Epoch 367, change: 0.00937692\n",
      "Epoch 368, change: 0.00782384\n",
      "Epoch 369, change: 0.00491592\n",
      "Epoch 370, change: 0.00111698\n",
      "Epoch 371, change: 0.00184679\n",
      "Epoch 372, change: 0.00134492\n",
      "Epoch 373, change: 0.01232011\n",
      "Epoch 374, change: 0.00510190\n",
      "Epoch 375, change: 0.02981722\n",
      "Epoch 376, change: 0.02572016\n",
      "Epoch 377, change: 0.00598379\n",
      "Epoch 378, change: 0.01252734\n",
      "Epoch 379, change: 0.00275404\n",
      "Epoch 380, change: 0.02124118\n",
      "Epoch 381, change: 0.02289964\n",
      "Epoch 382, change: 0.00090897\n",
      "Epoch 383, change: 0.00340987\n",
      "Epoch 384, change: 0.01587698\n",
      "Epoch 385, change: 0.02153659\n",
      "Epoch 386, change: 0.00097467\n",
      "Epoch 387, change: 0.00662492\n",
      "Epoch 388, change: 0.00446243\n",
      "Epoch 389, change: 0.01207889\n",
      "Epoch 390, change: 0.02215191\n",
      "Epoch 391, change: 0.02442015\n",
      "Epoch 392, change: 0.00735703\n",
      "Epoch 393, change: 0.01136776\n",
      "Epoch 394, change: 0.00104999\n",
      "Epoch 395, change: 0.02264493\n",
      "Epoch 396, change: 0.01648723\n",
      "Epoch 397, change: 0.01733238\n",
      "Epoch 398, change: 0.00349014\n",
      "Epoch 399, change: 0.03001180\n",
      "Epoch 400, change: 0.00628098\n",
      "Epoch 401, change: 0.00266780\n",
      "Epoch 402, change: 0.02714984\n",
      "Epoch 403, change: 0.01921677\n",
      "Epoch 404, change: 0.01907025\n",
      "Epoch 405, change: 0.01907839\n",
      "Epoch 406, change: 0.02594672\n",
      "Epoch 407, change: 0.00549376\n",
      "Epoch 408, change: 0.00315228\n",
      "Epoch 409, change: 0.00584155\n",
      "Epoch 410, change: 0.00173411\n",
      "Epoch 411, change: 0.00520034\n",
      "Epoch 412, change: 0.00210562\n",
      "Epoch 413, change: 0.00196085\n",
      "Epoch 414, change: 0.00179061\n",
      "Epoch 415, change: 0.00185225\n",
      "Epoch 416, change: 0.00060439\n",
      "Epoch 417, change: 0.01953822\n",
      "Epoch 418, change: 0.00327329\n",
      "Epoch 419, change: 0.00302401\n",
      "Epoch 420, change: 0.00621537\n",
      "Epoch 421, change: 0.01812616\n",
      "Epoch 422, change: 0.00396167\n",
      "Epoch 423, change: 0.00255158\n",
      "Epoch 424, change: 0.00383721\n",
      "Epoch 425, change: 0.00050805\n",
      "Epoch 426, change: 0.00261801\n",
      "Epoch 427, change: 0.00262726\n",
      "Epoch 428, change: 0.00103294\n",
      "Epoch 429, change: 0.00138355\n",
      "Epoch 430, change: 0.00162822\n",
      "Epoch 431, change: 0.00011359\n",
      "Epoch 432, change: 0.01134110\n",
      "Epoch 433, change: 0.01134110\n",
      "Epoch 434, change: 0.00213013\n",
      "Epoch 435, change: 0.00210322\n",
      "Epoch 436, change: 0.00067809\n",
      "Epoch 437, change: 0.01600576\n",
      "Epoch 438, change: 0.01615685\n",
      "Epoch 439, change: 0.00276160\n",
      "Epoch 440, change: 0.01765419\n",
      "Epoch 441, change: 0.00461318\n",
      "Epoch 442, change: 0.00132484\n",
      "Epoch 443, change: 0.00779222\n",
      "Epoch 444, change: 0.02031527\n",
      "Epoch 445, change: 0.00568215\n",
      "Epoch 446, change: 0.00859599\n",
      "Epoch 447, change: 0.01195707\n",
      "Epoch 448, change: 0.00270675\n",
      "Epoch 449, change: 0.00499302\n",
      "Epoch 450, change: 0.00935944\n",
      "Epoch 451, change: 0.00867626\n",
      "Epoch 452, change: 0.00855550\n",
      "Epoch 453, change: 0.01517065\n",
      "Epoch 454, change: 0.00204874\n",
      "Epoch 455, change: 0.00173565\n",
      "Epoch 456, change: 0.00090885\n",
      "Epoch 457, change: 0.01966955\n",
      "Epoch 458, change: 0.01254084\n",
      "Epoch 459, change: 0.01631928\n",
      "Epoch 460, change: 0.01552588\n",
      "Epoch 461, change: 0.01137957\n",
      "Epoch 462, change: 0.02179939\n",
      "Epoch 463, change: 0.02280229\n",
      "Epoch 464, change: 0.01709103\n",
      "Epoch 465, change: 0.00308175\n",
      "Epoch 466, change: 0.00245125\n",
      "Epoch 467, change: 0.00545951\n",
      "Epoch 468, change: 0.01514298\n",
      "Epoch 469, change: 0.00414136\n",
      "Epoch 470, change: 0.02417725\n",
      "Epoch 471, change: 0.01133452\n",
      "Epoch 472, change: 0.00139934\n",
      "Epoch 473, change: 0.00212226\n",
      "Epoch 474, change: 0.00555150\n",
      "Epoch 475, change: 0.00336960\n",
      "Epoch 476, change: 0.01862958\n",
      "Epoch 477, change: 0.00296722\n",
      "Epoch 478, change: 0.00745994\n",
      "Epoch 479, change: 0.00222383\n",
      "Epoch 480, change: 0.00274427\n",
      "Epoch 481, change: 0.00643037\n",
      "Epoch 482, change: 0.01967492\n",
      "Epoch 483, change: 0.00866304\n",
      "Epoch 484, change: 0.00189910\n",
      "Epoch 485, change: 0.01109266\n",
      "Epoch 486, change: 0.00819520\n",
      "Epoch 487, change: 0.00471389\n",
      "Epoch 488, change: 0.00927056\n",
      "Epoch 489, change: 0.02084532\n",
      "Epoch 490, change: 0.02449786\n",
      "Epoch 491, change: 0.01862228\n",
      "Epoch 492, change: 0.00409409\n",
      "Epoch 493, change: 0.02512276\n",
      "Epoch 494, change: 0.00472156\n",
      "Epoch 495, change: 0.00112495\n",
      "Epoch 496, change: 0.00104819\n",
      "Epoch 497, change: 0.01544977\n",
      "Epoch 498, change: 0.01135993\n",
      "Epoch 499, change: 0.00257531\n",
      "Epoch 500, change: 0.00438176\n",
      "Epoch 501, change: 0.01172835\n",
      "Epoch 502, change: 0.01273877\n",
      "Epoch 503, change: 0.00883234\n",
      "Epoch 504, change: 0.02555574\n",
      "Epoch 505, change: 0.01863434\n",
      "Epoch 506, change: 0.01570620\n",
      "Epoch 507, change: 0.02170244\n",
      "Epoch 508, change: 0.00736987\n",
      "Epoch 509, change: 0.00450778\n",
      "Epoch 510, change: 0.01299153\n",
      "Epoch 511, change: 0.03029111\n",
      "Epoch 512, change: 0.01547616\n",
      "Epoch 513, change: 0.02393237\n",
      "Epoch 514, change: 0.00308942\n",
      "Epoch 515, change: 0.00615423\n",
      "Epoch 516, change: 0.01392043\n",
      "Epoch 517, change: 0.01459362\n",
      "Epoch 518, change: 0.00144959\n",
      "Epoch 519, change: 0.00460924\n",
      "Epoch 520, change: 0.00292995\n",
      "Epoch 521, change: 0.00087736\n",
      "Epoch 522, change: 0.01867534\n",
      "Epoch 523, change: 0.01687979\n",
      "Epoch 524, change: 0.00221782\n",
      "Epoch 525, change: 0.02158162\n",
      "Epoch 526, change: 0.02252562\n",
      "Epoch 527, change: 0.00189669\n",
      "Epoch 528, change: 0.00613774\n",
      "Epoch 529, change: 0.00554717\n",
      "Epoch 530, change: 0.01317380\n",
      "Epoch 531, change: 0.00440390\n",
      "Epoch 532, change: 0.00058532\n",
      "Epoch 533, change: 0.00343506\n",
      "Epoch 534, change: 0.00418777\n",
      "Epoch 535, change: 0.00295096\n",
      "Epoch 536, change: 0.00684701\n",
      "Epoch 537, change: 0.01349846\n",
      "Epoch 538, change: 0.00096462\n",
      "Epoch 539, change: 0.00095716\n",
      "Epoch 540, change: 0.00996495\n",
      "Epoch 541, change: 0.00872650\n",
      "Epoch 542, change: 0.00276522\n",
      "Epoch 543, change: 0.02316827\n",
      "Epoch 544, change: 0.00118234\n",
      "Epoch 545, change: 0.00588949\n",
      "Epoch 546, change: 0.00582963\n",
      "Epoch 547, change: 0.01983462\n",
      "Epoch 548, change: 0.01552964\n",
      "Epoch 549, change: 0.01229810\n",
      "Epoch 550, change: 0.01435290\n",
      "Epoch 551, change: 0.01016712\n",
      "Epoch 552, change: 0.01042326\n",
      "Epoch 553, change: 0.02125735\n",
      "Epoch 554, change: 0.01770838\n",
      "Epoch 555, change: 0.00733541\n",
      "Epoch 556, change: 0.01612804\n",
      "Epoch 557, change: 0.01212010\n",
      "Epoch 558, change: 0.01191702\n",
      "Epoch 559, change: 0.01079381\n",
      "Epoch 560, change: 0.01713887\n",
      "Epoch 561, change: 0.01805928\n",
      "Epoch 562, change: 0.00346516\n",
      "Epoch 563, change: 0.00905417\n",
      "Epoch 564, change: 0.00246041\n",
      "Epoch 565, change: 0.00324352\n",
      "Epoch 566, change: 0.00491447\n",
      "Epoch 567, change: 0.00154402\n",
      "Epoch 568, change: 0.00098932\n",
      "Epoch 569, change: 0.00127469\n",
      "Epoch 570, change: 0.01847824\n",
      "Epoch 571, change: 0.01892934\n",
      "Epoch 572, change: 0.02578257\n",
      "Epoch 573, change: 0.02316186\n",
      "Epoch 574, change: 0.00954651\n",
      "Epoch 575, change: 0.00758718\n",
      "Epoch 576, change: 0.01352553\n",
      "Epoch 577, change: 0.00526849\n",
      "Epoch 578, change: 0.01072248\n",
      "Epoch 579, change: 0.01431645\n",
      "Epoch 580, change: 0.00947929\n",
      "Epoch 581, change: 0.01396767\n",
      "Epoch 582, change: 0.00092207\n",
      "Epoch 583, change: 0.01305344\n",
      "Epoch 584, change: 0.02619319\n",
      "Epoch 585, change: 0.00870938\n",
      "Epoch 586, change: 0.00517709\n",
      "Epoch 587, change: 0.00299419\n",
      "Epoch 588, change: 0.00293567\n",
      "Epoch 589, change: 0.00257752\n",
      "Epoch 590, change: 0.00180525\n",
      "Epoch 591, change: 0.00419717\n",
      "Epoch 592, change: 0.00666058\n",
      "Epoch 593, change: 0.01173107\n",
      "Epoch 594, change: 0.00276297\n",
      "Epoch 595, change: 0.00752562\n",
      "Epoch 596, change: 0.00419158\n",
      "Epoch 597, change: 0.00119627\n",
      "Epoch 598, change: 0.00470534\n",
      "Epoch 599, change: 0.00435803\n",
      "Epoch 600, change: 0.01505630\n",
      "Epoch 601, change: 0.01676445\n",
      "Epoch 602, change: 0.02389978\n",
      "Epoch 603, change: 0.00415953\n",
      "Epoch 604, change: 0.00578023\n",
      "Epoch 605, change: 0.00272556\n",
      "Epoch 606, change: 0.00228379\n",
      "Epoch 607, change: 0.00120220\n",
      "Epoch 608, change: 0.00536788\n",
      "Epoch 609, change: 0.01908353\n",
      "Epoch 610, change: 0.01524955\n",
      "Epoch 611, change: 0.00292464\n",
      "Epoch 612, change: 0.00309383\n",
      "Epoch 613, change: 0.00117516\n",
      "Epoch 614, change: 0.01180997\n",
      "Epoch 615, change: 0.00979451\n",
      "Epoch 616, change: 0.00202298\n",
      "Epoch 617, change: 0.00498960\n",
      "Epoch 618, change: 0.00538025\n",
      "Epoch 619, change: 0.00189725\n",
      "Epoch 620, change: 0.00307509\n",
      "Epoch 621, change: 0.01983298\n",
      "Epoch 622, change: 0.01339482\n",
      "Epoch 623, change: 0.01326793\n",
      "Epoch 624, change: 0.04363219\n",
      "Epoch 625, change: 0.00772514\n",
      "Epoch 626, change: 0.00408745\n",
      "Epoch 627, change: 0.00392368\n",
      "Epoch 628, change: 0.00482633\n",
      "Epoch 629, change: 0.00455272\n",
      "Epoch 630, change: 0.00997631\n",
      "Epoch 631, change: 0.00174042\n",
      "Epoch 632, change: 0.00241179\n",
      "Epoch 633, change: 0.00238425\n",
      "Epoch 634, change: 0.01987571\n",
      "Epoch 635, change: 0.01704431\n",
      "Epoch 636, change: 0.00430597\n",
      "Epoch 637, change: 0.00345726\n",
      "Epoch 638, change: 0.00346119\n",
      "Epoch 639, change: 0.02104631\n",
      "Epoch 640, change: 0.00972500\n",
      "Epoch 641, change: 0.00829170\n",
      "Epoch 642, change: 0.01599435\n",
      "Epoch 643, change: 0.00367546\n",
      "Epoch 644, change: 0.00257446\n",
      "Epoch 645, change: 0.01890890\n",
      "Epoch 646, change: 0.00734211\n",
      "Epoch 647, change: 0.00751163\n",
      "Epoch 648, change: 0.00076465\n",
      "Epoch 649, change: 0.00215190\n",
      "Epoch 650, change: 0.01250895\n",
      "Epoch 651, change: 0.01241334\n",
      "Epoch 652, change: 0.00269413\n",
      "Epoch 653, change: 0.03009235\n",
      "Epoch 654, change: 0.00769636\n",
      "Epoch 655, change: 0.00605915\n",
      "Epoch 656, change: 0.00495483\n",
      "Epoch 657, change: 0.00245832\n",
      "Epoch 658, change: 0.01179053\n",
      "Epoch 659, change: 0.01168169\n",
      "Epoch 660, change: 0.00061780\n",
      "Epoch 661, change: 0.01395507\n",
      "Epoch 662, change: 0.00999063\n",
      "Epoch 663, change: 0.00641650\n",
      "Epoch 664, change: 0.01441176\n",
      "Epoch 665, change: 0.00772526\n",
      "Epoch 666, change: 0.00121886\n",
      "Epoch 667, change: 0.00890659\n",
      "Epoch 668, change: 0.00654777\n",
      "Epoch 669, change: 0.01696063\n",
      "Epoch 670, change: 0.01550161\n",
      "Epoch 671, change: 0.02001564\n",
      "Epoch 672, change: 0.01852928\n",
      "Epoch 673, change: 0.02413143\n",
      "Epoch 674, change: 0.01064220\n",
      "Epoch 675, change: 0.00162474\n",
      "Epoch 676, change: 0.01368342\n",
      "Epoch 677, change: 0.01527299\n",
      "Epoch 678, change: 0.00136892\n",
      "Epoch 679, change: 0.00225340\n",
      "Epoch 680, change: 0.00601282\n",
      "Epoch 681, change: 0.00673733\n",
      "Epoch 682, change: 0.01140314\n",
      "Epoch 683, change: 0.00147928\n",
      "Epoch 684, change: 0.01443300\n",
      "Epoch 685, change: 0.00861553\n",
      "Epoch 686, change: 0.00692025\n",
      "Epoch 68"
     ]
    }
   ],
   "source": [
    "## train log reg\n",
    "clf = LogisticRegression(\n",
    "    multi_class='multinomial',\n",
    "    solver='saga',  # better for multinomial + large data\n",
    "    max_iter=1000,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b50669-708e-4f41-b004-cdfc98d39ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluate model\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Macro F1-score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# Optional: Full classification report\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c5902d-b17a-40bc-b82c-a94f956a8d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save encoding data for reuse \n",
    "\n",
    "np.savez(\"convenz_onehot_data.npz\", X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, classes=le.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1bbda0-7db1-41ca-9f53-fbc2d03a5eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize model coefficients\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualize coefficient heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(clf.coef_, cmap=\"coolwarm\", center=0, xticklabels=False)\n",
    "plt.xlabel(\"One-hot features (512 Ã— 4)\")\n",
    "plt.ylabel(\"EC Label Index\")\n",
    "plt.title(\"Logistic Regression Weights (One-hot DNA)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0300f8ab-97ef-45b7-a4c5-e92e3500daaa",
   "metadata": {},
   "source": [
    "## K-mer Count Feature Variant (e.g., 4-mers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea98b70e-01a6-42c8-83b9-6c7d6b40f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import product\n",
    "\n",
    "# Vocabulary of all 4-mers\n",
    "k = 4\n",
    "kmer_vocab = [''.join(p) for p in product(\"ACGT\", repeat=k)]\n",
    "\n",
    "def kmer_features_dna(seq, k=4):\n",
    "    kmers = [seq[i:i+k] for i in range(len(seq)-k+1)]\n",
    "    counts = Counter(kmers)\n",
    "    return np.array([counts.get(kmer, 0) for kmer in kmer_vocab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28c5245-adf5-4813-8f2e-fbf0d549aab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_kmer = np.stack(df_train[\"Sequence\"].map(kmer_features_dna))\n",
    "X_test_kmer = np.stack(df_test[\"Sequence\"].map(kmer_features_dna))\n",
    "\n",
    "print(\"Shape of k-mer feature matrix:\", X_train_kmer.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13bc4d9-d04b-487c-ae53-1276eb7ebe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrain log reg\n",
    "clf_kmer = LogisticRegression(\n",
    "    multi_class='multinomial',\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "clf_kmer.fit(X_train_kmer, y_train)\n",
    "\n",
    "y_pred_kmer = clf_kmer.predict(X_test_kmer)\n",
    "print(\"K-mer Accuracy:\", accuracy_score(y_test, y_pred_kmer))\n",
    "print(\"K-mer F1-score (macro):\", f1_score(y_test, y_pred_kmer, average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e401bf58-83c0-4c44-beae-bbc86612ddac",
   "metadata": {},
   "source": [
    "## cross val evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a74d3-71c9-408b-8562-1d0a0989cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(\n",
    "    clf,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"5-fold cross-validated F1 scores:\", scores)\n",
    "print(\"Mean F1:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5aceca-d174-420a-8f6d-1320dd0b36e6",
   "metadata": {},
   "source": [
    "## blast based evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21a41d9-0750-40cd-821d-d24b834229b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1: write sequences to fasta\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Write training sequences\n",
    "train_records = [\n",
    "    SeqRecord(Seq(seq), id=entry, description=label)\n",
    "    for seq, entry, label in zip(df_train[\"Sequence\"], df_train[\"Entry\"], df_train[\"Label\"])\n",
    "]\n",
    "SeqIO.write(train_records, \"train_set.fasta\", \"fasta\")\n",
    "\n",
    "# Write test sequences\n",
    "test_records = [\n",
    "    SeqRecord(Seq(seq), id=entry, description=label)\n",
    "    for seq, entry, label in zip(df_test[\"Sequence\"], df_test[\"Entry\"], df_test[\"Label\"])\n",
    "]\n",
    "SeqIO.write(test_records, \"test_set.fasta\", \"fasta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa33818-94b4-4211-88cc-f588d9bcd923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2 : create BLAST DB\n",
    "makeblastdb -in train_set.fasta -dbtype nucl -out train_db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5909c972-f81c-4ac3-874e-bdfa6cafefd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3- run blast\n",
    "blastn -query test_set.fasta -db train_db -outfmt \"6 qseqid sseqid pident length\" -out blast_results.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bec748f-cc44-4711-b257-d01884694169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 4: parse blast files\n",
    "blast_df = pd.read_csv(\"blast_results.txt\", sep=\"\\t\", header=None, names=[\"query\", \"subject\", \"pident\", \"length\"])\n",
    "\n",
    "# Take best hit per test query\n",
    "top_hits = blast_df.sort_values([\"query\", \"pident\", \"length\"], ascending=[True, False, False]).drop_duplicates(\"query\")\n",
    "\n",
    "# Map training subject ID to EC label\n",
    "entry_to_label = dict(zip(df_train[\"Entry\"], df_train[\"Label\"]))\n",
    "predicted_labels = top_hits[\"subject\"].map(entry_to_label)\n",
    "true_labels = df_test.set_index(\"Entry\").loc[top_hits[\"query\"], \"Label\"].values\n",
    "\n",
    "# Evaluate\n",
    "print(\"BLAST Accuracy:\", accuracy_score(true_labels, predicted_labels))\n",
    "print(\"BLAST Macro F1:\", f1_score(true_labels, predicted_labels, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645b7e97-66bd-4bf2-9ef3-6e9270e8e88d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:esmfold]",
   "language": "python",
   "name": "conda-env-esmfold-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
